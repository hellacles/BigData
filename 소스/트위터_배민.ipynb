{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **트위터 '배민커넥트' 끌어오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 트위터 API로 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "api_key = \"RvnZeIl8ra88reu8fm23m0bST\"\n",
    "api_secret = \"wTRylK94GK2KmhZUnqXonDaIszwAsS6VPvpSsIo6EX5GQLtzQo\"\n",
    "access_token = \"959614462004117506-dkWyZaO8Bz3ZXh73rspWfc1sQz0EnDU\"\n",
    "access_token_secret = \"rxDWfg7uz1yXMTDwijz0x90yWhDAnmOM15R6IgC8kmtTe\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# twitter API를 사용하기 위한 준비\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data 0.2 % complete..\n",
      "Get data 0.4 % complete..\n",
      "Get data 0.6 % complete..\n",
      "Get data 0.8 % complete..\n",
      "Get data 1.0 % complete..\n",
      "Get data 1.2 % complete..\n",
      "Get data 1.4000000000000001 % complete..\n",
      "Get data 1.6 % complete..\n",
      "Get data 1.7999999999999998 % complete..\n",
      "Get data 2.0 % complete..\n",
      "Get data 2.1999999999999997 % complete..\n",
      "Get data 2.4 % complete..\n",
      "Get data 2.6 % complete..\n",
      "Get data 2.8000000000000003 % complete..\n",
      "Get data 3.0 % complete..\n",
      "Get data 3.2 % complete..\n",
      "Get data 3.4000000000000004 % complete..\n",
      "Get data 3.5999999999999996 % complete..\n",
      "Get data 3.8 % complete..\n",
      "Get data 4.0 % complete..\n",
      "Get data 4.2 % complete..\n",
      "Get data 4.3999999999999995 % complete..\n",
      "Get data 4.6 % complete..\n",
      "Get data 4.8 % complete..\n",
      "Get data 5.0 % complete..\n",
      "Get data 5.2 % complete..\n",
      "Get data 5.4 % complete..\n",
      "Get data 5.6000000000000005 % complete..\n",
      "Get data 5.800000000000001 % complete..\n",
      "Get data 6.0 % complete..\n",
      "Get data 6.2 % complete..\n",
      "Get data 6.4 % complete..\n",
      "Get data 6.6000000000000005 % complete..\n",
      "Get data 6.800000000000001 % complete..\n",
      "Get data 7.000000000000001 % complete..\n",
      "Get data 7.199999999999999 % complete..\n",
      "Get data 7.3999999999999995 % complete..\n",
      "Get data 7.6 % complete..\n",
      "Get data 7.8 % complete..\n",
      "Get data 8.0 % complete..\n",
      "Get data 8.200000000000001 % complete..\n",
      "Get data 8.4 % complete..\n",
      "Get data 8.6 % complete..\n",
      "Get data 8.799999999999999 % complete..\n",
      "Get data 9.0 % complete..\n",
      "Get data 9.2 % complete..\n",
      "Get data 9.4 % complete..\n",
      "Get data 9.6 % complete..\n",
      "Get data 9.8 % complete..\n",
      "Get data 10.0 % complete..\n",
      "Get data 10.2 % complete..\n",
      "Get data 10.4 % complete..\n",
      "Get data 10.6 % complete..\n",
      "Get data 10.8 % complete..\n",
      "Get data 11.0 % complete..\n",
      "Get data 11.200000000000001 % complete..\n",
      "Get data 11.4 % complete..\n",
      "Get data 11.600000000000001 % complete..\n",
      "Get data 11.799999999999999 % complete..\n",
      "Get data 12.0 % complete..\n",
      "Get data 12.2 % complete..\n",
      "Get data 12.4 % complete..\n",
      "Get data 12.6 % complete..\n",
      "Get data 12.8 % complete..\n",
      "Get data 13.0 % complete..\n",
      "Get data 13.200000000000001 % complete..\n",
      "Get data 13.4 % complete..\n",
      "Get data 13.600000000000001 % complete..\n",
      "Get data 13.8 % complete..\n",
      "Get data 14.000000000000002 % complete..\n",
      "Get data 14.2 % complete..\n",
      "Get data 14.399999999999999 % complete..\n",
      "Get data 14.6 % complete..\n",
      "Get data 14.799999999999999 % complete..\n",
      "Get data 15.0 % complete..\n",
      "Get data 15.2 % complete..\n",
      "Get data 15.4 % complete..\n",
      "Get data 15.6 % complete..\n",
      "Get data 15.8 % complete..\n",
      "Get data 16.0 % complete..\n",
      "Get data 16.2 % complete..\n",
      "Get data 16.400000000000002 % complete..\n",
      "Get data 16.6 % complete..\n",
      "Get data 16.8 % complete..\n",
      "Get data 17.0 % complete..\n",
      "Get data 17.2 % complete..\n",
      "Get data 17.4 % complete..\n",
      "Get data 17.599999999999998 % complete..\n",
      "Get data 17.8 % complete..\n",
      "Get data 18.0 % complete..\n",
      "Get data 18.2 % complete..\n",
      "Get data 18.4 % complete..\n",
      "Get data 18.6 % complete..\n",
      "Get data 18.8 % complete..\n",
      "Get data 19.0 % complete..\n",
      "Get data 19.2 % complete..\n",
      "Get data 19.400000000000002 % complete..\n",
      "Get data 19.6 % complete..\n",
      "Get data 19.8 % complete..\n",
      "Get data 100 % complete..\n"
     ]
    }
   ],
   "source": [
    "# 크롤링된 데이터를 저장할 데이터 프레임\n",
    "# 15분에 한번씩만 가능\n",
    "\n",
    "columns = ['created', 'tweet_text']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "keyword='식었음'\n",
    "\n",
    "# twitter API를 사용하여 ‘쿠리어’이 포함된 100페이지의 트윗들을 크롤링한 뒤, ‘text’, ‘created_at’ 정보를 데이터 프레임으로 저장\n",
    "for i in range(1,100):\n",
    "    print(\"Get data\", str(i/500*100), \"% complete..\")\n",
    "    tweets = api.search(keyword)\n",
    "    for tweet in tweets:\n",
    "        tweet_text = tweet.text\n",
    "        created = tweet.created_at\n",
    "        row = [created, tweet_text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df = df.append(series, ignore_index=True)\n",
    "print(\"Get data 100 % complete..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./fusion/data/tweet_temp4.csv\", index=False)\n",
    "# tweet_Temp는 '배민커넥터' 였음\n",
    "# tweet_Temp2는 '배민'\n",
    "# tweet_Temp3는 '배민커넥' \n",
    "# tweet_Temp4는 '식었음' --> 나이트 삐기 데이터..\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-20 07:08:51</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-20 05:05:33</td>\n",
       "      <td>아ㅋㅋ 친구가 O딘 영상 보여줘서 보는데, 시네마틱 되게 잘뽑았다 디자인 좋다 이러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-20 04:25:14</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-20 04:23:58</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-20 04:05:56</td>\n",
       "      <td>RT @cumo_0: 졍우한테 돈세노 가사 따와서..\\n잠깐 식었던 시간동안 그냥 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>2020-11-20 02:45:40</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>2020-11-20 02:33:03</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>2020-11-20 02:31:54</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2020-11-20 02:29:10</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>2020-11-20 02:28:20</td>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created                                         tweet_text\n",
       "0     2020-11-20 07:08:51  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1     2020-11-20 05:05:33  아ㅋㅋ 친구가 O딘 영상 보여줘서 보는데, 시네마틱 되게 잘뽑았다 디자인 좋다 이러...\n",
       "2     2020-11-20 04:25:14  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "3     2020-11-20 04:23:58  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "4     2020-11-20 04:05:56  RT @cumo_0: 졍우한테 돈세노 가사 따와서..\\n잠깐 식었던 시간동안 그냥 ...\n",
       "...                   ...                                                ...\n",
       "1480  2020-11-20 02:45:40  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1481  2020-11-20 02:33:03  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1482  2020-11-20 02:31:54  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1483  2020-11-20 02:29:10  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1484  2020-11-20 02:28:20  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "\n",
       "[1485 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet = pd.read_csv(\"./fusion/data/tweet_temp4.csv\")\n",
    "display(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거합니다.\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글 처음부터 끝을 알리는 정규표현식\n",
    "    result = hangul.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘tweet_text’ 피처에 이를 적용합니다.\n",
    "tweet['ko_text'] = tweet['tweet_text'].apply(lambda x: text_cleaning(x))\n",
    "tweet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 한국어 약식 불용어사전 예시 파일입니다. 출처 - (https://www.ranks.nl/stopwords/korean)\n",
    "korean_stopwords_path = \"./fusion/data/korean_stopwords.txt\"\n",
    "with open(korean_stopwords_path, encoding='utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "\n",
    "def get_nouns(x):\n",
    "    nouns_tagger = Okt()\n",
    "    nouns = nouns_tagger.nouns(x)\n",
    "    \n",
    "    # 한글자 키워드를 제거합니다.\n",
    "    nouns = [noun for noun in nouns if len(noun) > 1]\n",
    "    \n",
    "    # 불용어를 제거합니다.\n",
    "    nouns = [noun for noun in nouns if noun not in stopwords]\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘ko_text’ 피처에 이를 적용합니다.\n",
    "tweet['nouns'] = tweet['ko_text'].apply(lambda x: get_nouns(x))\n",
    "print(df.shape)\n",
    "tweet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.to_excel(\"./fusion/data/tweeter_result4.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연관분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# 장바구니 형태의 데이터(트랜잭션 데이터)를 생성\n",
    "transactions = [\n",
    "    ['쿠팡', '현실'],\n",
    "    ['쿠리어', '소득'],\n",
    "    ['배민', '쿠리어', '후기']\n",
    "]\n",
    "\n",
    "# 연관 분석을 수행\n",
    "results = list(apriori(transactions))\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 형태로 정리\n",
    "columns = ['source', 'target', 'support']\n",
    "network_tweet = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 규칙의 조건절을 source, 결과절을 target, 지지도를 support 라는 데이터 프레임의 피처로 변환\n",
    "for result in results:\n",
    "    if len(result.items) == 2:\n",
    "        items = [x for x in result.items]\n",
    "        row = [items[0], items[1], result.support]\n",
    "        series = pd.Series(row, index=network_tweet.columns)\n",
    "        network_tweet = network_tweet.append(series, ignore_index=True)\n",
    "\n",
    "network_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜잭션 데이터를 추출\n",
    "transactions = tweet['nouns'].tolist()\n",
    "#transactions = [transaction for transaction in transactions if transaction] # 공백 문자열을 방지합니다.\n",
    "print(transactions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연관 분석을 수행합니다.\n",
    "# results = list(apriori(transactions,\n",
    "#                         min_support=0.1))\n",
    "# print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 형태로 정리\n",
    "columns = ['source', 'target', 'support']\n",
    "network_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 규칙의 조건절을 source, 결과절을 target, 지지도를 support 라는 데이터 프레임의 피처로 변환합니다.\n",
    "for result in results:\n",
    "    if len(result.items) == 2:\n",
    "        items = [x for x in result.items]\n",
    "        row = [items[0], items[1], result.support]\n",
    "        series = pd.Series(row, index=network_df.columns)\n",
    "        network_df = network_df.append(series, ignore_index=True)\n",
    "\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 말뭉치로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_corpus = \"\".join(tweet['ko_text'].tolist())\n",
    "print(tweet_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "# 명사 키워드를 추출\n",
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(tweet_corpus)\n",
    "count = Counter(nouns)\n",
    "\n",
    "# 한글자 키워드를 제거\n",
    "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
    "print(remove_char_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 결과를 보기 쉽게 display\n",
    "# 키워드와 키워드 빈도 점수를 ‘node’, ‘nodesize’ 라는 데이터 프레임의 피처로 생성\n",
    "node_df = pd.DataFrame(remove_char_counter.items(), columns=['node', 'nodesize'])\n",
    "node_df = node_df[node_df['nodesize'] >= 50] # 시각화의 편의를 위해 ‘nodesize’ 50 이하는 제거\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연관 키워드 네트워크 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install networkx\n",
    "import networkx as nx\n",
    "plt.figure(figsize=(25,25))\n",
    "\n",
    "# networkx 그래프 객체를 생성합니다.\n",
    "G = nx.Graph()\n",
    "\n",
    "# node_df의 키워드 빈도수를 데이터로 하여, 네트워크 그래프의 ‘노드’ 역할을 하는 원을 생성합니다.\n",
    "for index, row in node_df.iterrows():\n",
    "    G.add_node(row['node'], nodesize=row['nodesize'])\n",
    "    \n",
    "# network_df의 연관 분석 데이터를 기반으로, 네트워크 그래프의 ‘관계’ 역할을 하는 선을 생성합니다.\n",
    "for index, row in network_df.iterrows():\n",
    "    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n",
    "    \n",
    "# 그래프 디자인과 관련된 파라미터를 설정\n",
    "pos = nx.spring_layout(G, k=0.6, iterations=50)\n",
    "sizes = [G.nodes[node]['nodesize']*25 for node in G]\n",
    "nx.draw(G, pos=pos, node_size=sizes)\n",
    "\n",
    "# Windows 사용자는 AppleGothic 대신,'Malgun Gothic'. 그 외 OS는 OS에서 한글을 지원하는 기본 폰트를 입력합니다.\n",
    "nx.draw_networkx_labels(G, pos=pos, font_family='Malgun Gothic', font_size=25)\n",
    "\n",
    "# 그래프를 출력합니다.\n",
    "ax = plt.gca()\n",
    "plt.savefig(\"./fusion/data/네트워크 결과.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석 따라해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 참고해보자\n",
    "# https://cyc1am3n.github.io/2018/11/10/classifying_korean_movie_review.html\n",
    "# 감성분석은 테스트 데이터를 만들어 학습시켜야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judge = pd.read_excel('./fusion/data/for_train.xlsx')\n",
    "# display(judge)\n",
    "judge_1 = judge['text']\n",
    "# display(judge_1)\n",
    "reality = pd.unique(judge_1)\n",
    "df_real = pd.DataFrame(reality)\n",
    "display(df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judge = pd.read_excel('./fusion/data/tweeter_result2.xlsx')\n",
    "# display(judge)\n",
    "judge_1 = judge['ko_text']\n",
    "# display(judge_1)\n",
    "reality = pd.unique(judge_1)\n",
    "df_real = pd.DataFrame(reality)\n",
    "display(df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judge = pd.read_excel('./fusion/data/tweeter_result3.xlsx')\n",
    "# display(judge)\n",
    "judge_1 = judge['ko_text']\n",
    "# display(judge_1)\n",
    "reality = pd.unique(judge_1)\n",
    "df_real = pd.DataFrame(reality)\n",
    "display(df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>아ㅋㅋ 친구가 O딘 영상 보여줘서 보는데, 시네마틱 되게 잘뽑았다 디자인 좋다 이러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @cumo_0: 졍우한테 돈세노 가사 따와서..\\n잠깐 식었던 시간동안 그냥 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>화장실에서 이 짓 하다가 **하는 들신을 방금 생각했는데 .. ..  . **하고 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  RT @FF14_Orte: 근데 자만추 점점 클럽? 나이트? 분위기가 디폴트로 되어...\n",
       "1  아ㅋㅋ 친구가 O딘 영상 보여줘서 보는데, 시네마틱 되게 잘뽑았다 디자인 좋다 이러...\n",
       "2  RT @cumo_0: 졍우한테 돈세노 가사 따와서..\\n잠깐 식었던 시간동안 그냥 ...\n",
       "3  화장실에서 이 짓 하다가 **하는 들신을 방금 생각했는데 .. ..  . **하고 ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "judge = pd.read_csv('./fusion/data/tweet_temp4.csv')\n",
    "# display(judge)\n",
    "judge_1 = judge['tweet_text']\n",
    "# display(judge_1)\n",
    "reality = pd.unique(judge_1)\n",
    "df_real = pd.DataFrame(reality)\n",
    "display(df_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
